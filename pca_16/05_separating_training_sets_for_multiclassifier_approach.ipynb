{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating training sets for multiclassifier approach\n",
    "\n",
    "In this notebook we split the `lab_ids` in groups ang generate training/val test sets for each of these groups. We have already seen that there are `1314`unique lab ids. Our strategy here will be to separate `9` subsets of lab ids, each containing `146`lab_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 533 ms, sys: 39.8 ms, total: 573 ms\n",
      "Wall time: 572 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, defaultdict, Counter\n",
    "import seaborn as sns\n",
    "import json\n",
    "#from sklearn.decomposition import PCA\n",
    "#from joblib import dump, load\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent_dir = \"/content/genetic_engineering_attribution\"\n",
    "parent_dir = \"/home/rio/data_sets/genetic_engineering_attribution\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rio/anaconda3/envs/genetic_attribution/lib/python3.8/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df_full_train: (1971000, 91)\n",
      "Shape of df_test: (1881600, 91)\n",
      "CPU times: user 29.7 s, sys: 1.49 s, total: 31.1 s\n",
      "Wall time: 31.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### pca directory\n",
    "pca_dir = os.path.join(parent_dir,\"pca\")\n",
    "\n",
    "### pca engineered data sets\n",
    "pca_engineered_datasets_dir = os.path.join(parent_dir,\"pca_engineered_datasets\")\n",
    "\n",
    "### pca_32_95comp dir\n",
    "pca_16_48comp_dir = os.path.join(pca_engineered_datasets_dir,\"pca_16_48comp\")\n",
    "train_val_test_dir = os.path.join(pca_16_48comp_dir,\"train_val_test\")\n",
    "\n",
    "### paths to csvs\n",
    "full_train_path = os.path.join(train_val_test_dir,\"full_train.csv\")\n",
    "#train_path = os.path.join(pca_32_95comp_dir,\"train.csv\")\n",
    "#val_path = os.path.join(pca_32_95comp_dir,\"val.csv\")\n",
    "test_path = os.path.join(train_val_test_dir,\"test.csv\")\n",
    "\n",
    "### loading dataframes\n",
    "df_full_train = pd.read_csv(full_train_path,index_col=0)\n",
    "#df_train = pd.read_csv(train_path,index_col=0)\n",
    "#df_val = pd.read_csv(val_path,index_col=0)\n",
    "df_test = pd.read_csv(test_path,index_col=0)\n",
    "\n",
    "### Printing shapes:\n",
    "print(f\"Shape of df_full_train: {df_full_train.shape}\")\n",
    "#print(f\"Shape of df_train: {df_train.shape}\")\n",
    "#print(f\"Shape of df_val: {df_val.shape}\")\n",
    "print(f\"Shape of df_test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>lab_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>pca_0</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>...</th>\n",
       "      <th>species_budding_yeast</th>\n",
       "      <th>species_fly</th>\n",
       "      <th>species_human</th>\n",
       "      <th>species_mouse</th>\n",
       "      <th>species_mustard_weed</th>\n",
       "      <th>species_nematode</th>\n",
       "      <th>species_other</th>\n",
       "      <th>species_rat</th>\n",
       "      <th>species_synthetic</th>\n",
       "      <th>species_zebrafish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34884</th>\n",
       "      <td>9ER34</td>\n",
       "      <td>A2A1R52R</td>\n",
       "      <td>AGATTCAGGTTACAAT</td>\n",
       "      <td>16</td>\n",
       "      <td>0.963592</td>\n",
       "      <td>-0.464117</td>\n",
       "      <td>0.052355</td>\n",
       "      <td>-0.013126</td>\n",
       "      <td>0.209852</td>\n",
       "      <td>0.419804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30686</th>\n",
       "      <td>QCVF4</td>\n",
       "      <td>2FCX4O0X</td>\n",
       "      <td>CAGCCAGCCAGACGCA</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.522922</td>\n",
       "      <td>-0.131776</td>\n",
       "      <td>0.173052</td>\n",
       "      <td>-0.802706</td>\n",
       "      <td>0.281142</td>\n",
       "      <td>-0.164166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23030</th>\n",
       "      <td>T9LTO</td>\n",
       "      <td>EKHYS325</td>\n",
       "      <td>ACGAGCAGCGCTTTGC</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.242151</td>\n",
       "      <td>-1.000646</td>\n",
       "      <td>-0.154113</td>\n",
       "      <td>-0.320270</td>\n",
       "      <td>-1.097626</td>\n",
       "      <td>-0.341326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>ETXJT</td>\n",
       "      <td>Q2K8NHZY</td>\n",
       "      <td>TTGACGAGTTCTTCTG</td>\n",
       "      <td>16</td>\n",
       "      <td>0.166205</td>\n",
       "      <td>-0.564415</td>\n",
       "      <td>0.541259</td>\n",
       "      <td>0.673667</td>\n",
       "      <td>-1.054254</td>\n",
       "      <td>-0.281294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>QWUAU</td>\n",
       "      <td>JPO7CTQP</td>\n",
       "      <td>TGCCAACCTGCTCATT</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.397965</td>\n",
       "      <td>0.592384</td>\n",
       "      <td>0.558828</td>\n",
       "      <td>0.670752</td>\n",
       "      <td>-0.561487</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34182</th>\n",
       "      <td>FD1GR</td>\n",
       "      <td>EMJXDINV</td>\n",
       "      <td>CCGATTATGCCAGCCT</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.295273</td>\n",
       "      <td>-0.158168</td>\n",
       "      <td>-0.113019</td>\n",
       "      <td>0.241383</td>\n",
       "      <td>0.223386</td>\n",
       "      <td>0.329199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23148</th>\n",
       "      <td>XRZMO</td>\n",
       "      <td>ICRBJL24</td>\n",
       "      <td>ACGGATGGTGATCCCC</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.742338</td>\n",
       "      <td>0.800034</td>\n",
       "      <td>0.263020</td>\n",
       "      <td>0.116042</td>\n",
       "      <td>-0.457552</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14899</th>\n",
       "      <td>U2VKI</td>\n",
       "      <td>1VPOX8VI</td>\n",
       "      <td>GGGTGCCACCAGAGGA</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.357624</td>\n",
       "      <td>-0.543644</td>\n",
       "      <td>-0.949499</td>\n",
       "      <td>-0.871873</td>\n",
       "      <td>0.608746</td>\n",
       "      <td>0.189836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sequence_id    lab_id          sequence  seq_length     pca_0     pca_1  \\\n",
       "34884       9ER34  A2A1R52R  AGATTCAGGTTACAAT          16  0.963592 -0.464117   \n",
       "30686       QCVF4  2FCX4O0X  CAGCCAGCCAGACGCA          16 -0.522922 -0.131776   \n",
       "23030       T9LTO  EKHYS325  ACGAGCAGCGCTTTGC          16 -0.242151 -1.000646   \n",
       "2404        ETXJT  Q2K8NHZY  TTGACGAGTTCTTCTG          16  0.166205 -0.564415   \n",
       "1788        QWUAU  JPO7CTQP  TGCCAACCTGCTCATT          16 -0.397965  0.592384   \n",
       "34182       FD1GR  EMJXDINV  CCGATTATGCCAGCCT          16 -0.295273 -0.158168   \n",
       "23148       XRZMO  ICRBJL24  ACGGATGGTGATCCCC          16 -0.742338  0.800034   \n",
       "14899       U2VKI  1VPOX8VI  GGGTGCCACCAGAGGA          16 -0.357624 -0.543644   \n",
       "\n",
       "          pca_2     pca_3     pca_4     pca_5  ...  species_budding_yeast  \\\n",
       "34884  0.052355 -0.013126  0.209852  0.419804  ...                    0.0   \n",
       "30686  0.173052 -0.802706  0.281142 -0.164166  ...                    0.0   \n",
       "23030 -0.154113 -0.320270 -1.097626 -0.341326  ...                    0.0   \n",
       "2404   0.541259  0.673667 -1.054254 -0.281294  ...                    0.0   \n",
       "1788   0.558828  0.670752 -0.561487  0.106409  ...                    0.0   \n",
       "34182 -0.113019  0.241383  0.223386  0.329199  ...                    0.0   \n",
       "23148  0.263020  0.116042 -0.457552 -0.036876  ...                    0.0   \n",
       "14899 -0.949499 -0.871873  0.608746  0.189836  ...                    0.0   \n",
       "\n",
       "       species_fly  species_human  species_mouse  species_mustard_weed  \\\n",
       "34884          0.0            0.0            1.0                   0.0   \n",
       "30686          1.0            0.0            0.0                   0.0   \n",
       "23030          0.0            0.0            0.0                   0.0   \n",
       "2404           0.0            0.0            0.0                   0.0   \n",
       "1788           0.0            0.0            1.0                   0.0   \n",
       "34182          0.0            0.0            0.0                   0.0   \n",
       "23148          0.0            0.0            0.0                   0.0   \n",
       "14899          0.0            1.0            0.0                   0.0   \n",
       "\n",
       "       species_nematode  species_other  species_rat  species_synthetic  \\\n",
       "34884               0.0            0.0          0.0                0.0   \n",
       "30686               0.0            0.0          0.0                0.0   \n",
       "23030               0.0            0.0          0.0                0.0   \n",
       "2404                0.0            0.0          0.0                0.0   \n",
       "1788                0.0            0.0          0.0                0.0   \n",
       "34182               0.0            0.0          0.0                1.0   \n",
       "23148               0.0            0.0          0.0                0.0   \n",
       "14899               0.0            0.0          0.0                0.0   \n",
       "\n",
       "       species_zebrafish  \n",
       "34884                0.0  \n",
       "30686                0.0  \n",
       "23030                1.0  \n",
       "2404                 0.0  \n",
       "1788                 0.0  \n",
       "34182                0.0  \n",
       "23148                0.0  \n",
       "14899                0.0  \n",
       "\n",
       "[8 rows x 91 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating train_splits dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dir(directory,delete_dir=True):\n",
    "    if not os.path.isdir(directory):\n",
    "        print(f\"Creating directory {directory}\")\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    elif delete_dir:\n",
    "        print(f\"Directory {directory} already exists. Deleting and recreating.\")\n",
    "        shutil.rmtree(directory)\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    else:\n",
    "        print(f\"Directory {directory} already exists. I will either overwrite or add files to it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_splits_dir = os.path.join(os.path.join(pca_32_95comp_dir,\"train_splits\"))\n",
    "#print(\"train_splits_dir: \", train_splits_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_dir = True\n",
    "#generate_dir(train_splits_dir,delete_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating lab_id split data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'a', 1: 'b', 2: 'c'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [\"a\", \"b\", \"c\"]\n",
    "dict(  zip( range(len(l)),l  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lab_id_datasets(df,n_lab_ids=9,batch_size=1000,impurity_ratio=3,savedir=None,delete_dir=True,\n",
    "                             verbose=False):\n",
    "    ### generating directories\n",
    "    data_dir = os.path.join(savedir,\"data\")\n",
    "    generate_dir(data_dir,delete_dir)\n",
    "    json_dir = os.path.join(savedir,\"json\")\n",
    "    generate_dir(json_dir,delete_dir)\n",
    "    \n",
    "    n_unique = len(df.lab_id.unique()) \n",
    "    assert n_unique%n_lab_ids ==0, f\"n_lab_ids must be a divisor of the number of unique lab_ids, {n_unique}\"\n",
    "    shuffled_lab_ids = np.random.permutation(np.unique(df.lab_id)).reshape(-1,n_lab_ids)\n",
    "    n_zeros = np.ceil(np.log10(n_unique//n_lab_ids).astype(int)).astype(int)\n",
    "    pbar = enumerate(shuffled_lab_ids)\n",
    "    batch_names_dict = {}\n",
    "    if verbose:\n",
    "        pbar = tqdm(pbar)\n",
    "    for ix, batch in pbar:\n",
    "        if verbose:\n",
    "            pbar.set_description(\"Processing batch [\"+\",\".join(batch)+\"]\\r\")\n",
    "        mask = df.lab_id.isin(batch)\n",
    "        df_batch = df.loc[mask,:]\n",
    "        if batch_size is not None:\n",
    "            #df_batch = pd.DataFrame({'col':np.random.randn(12000), 'target':np.random.randint(low = 0, high = 2, size=12000)})\n",
    "            df_batch = df_batch.groupby('lab_id').apply(lambda x: x.sample(n=batch_size))#.reset_index(drop = True)\n",
    "            df_batch.index = df_batch.index.get_level_values(1) \n",
    "        ### extracting random sample from out-of-batch classes\n",
    "        if impurity_ratio is not None:\n",
    "            df_impurity = df.loc[~mask,:].sample(impurity_ratio*batch_size,replace=True)\n",
    "        df_batch = pd.concat([df_batch,df_impurity])\n",
    "        ### saving df_batch\n",
    "        batch_name = f\"batch_{str(ix).zfill(n_zeros)}.csv\" \n",
    "        #filename = \"_\".join(batch)+\".csv\"\n",
    "        batch_path = os.path.join(data_dir,batch_name)\n",
    "        if verbose:\n",
    "            pbar.set_description(f\"Writing file {batch_path} to disk\")\n",
    "        df_batch.to_csv(batch_path,index=True)\n",
    "        ### building json batch dict\n",
    "        batch_names_dict[batch_name] = \"_\".join(batch)\n",
    "    print(\"Dumping json with batch names...\")\n",
    "    batch_names_dict_path = os.path.join(json_dir,\"batch_names.json\")\n",
    "    print(f\"Dumping json with batch names in {batch_names_dict_path}\")\n",
    "    with open(batch_names_dict_path, 'w') as fp:\n",
    "        json.dump(batch_names_dict, fp)  \n",
    "    print(\"Done.\")\n",
    "    \n",
    "def generate_splits(df,n_splits,n_lab_ids=9,batch_size=1000,impurity_ratio=3,savedir=None,delete_dir=True,verbose=False):\n",
    "    #generate_dir(savedir,delete_dir)\n",
    "    #if not os.path.isdir(savedir):\n",
    "    #    print(f\"Creating directory {savedir}\")\n",
    "    #    os.mkdir(savedir)\n",
    "    #elif delete_dir:\n",
    "    #    print(f\"Directory {savedir} already exists. Deleting an recreating.\")\n",
    "    #    shutil.rmtree(savedir)\n",
    "    #    os.mkdir(savedir)\n",
    "    #else:\n",
    "    #    print(f\"Directory {savedir} already exists. I will either overwrite or add files to it.\")\n",
    "    pbar = tqdm(range(n_splits))\n",
    "    zeros = np.ceil(np.log10(n_splits)).astype(int)\n",
    "    for s in pbar:\n",
    "        split_dir = os.path.join(savedir,\"split_\"+str(s).zfill(zeros))\n",
    "        ##generate_dir(split_dir,delete_dir)\n",
    "        #split_dir = os.path.join(split_dir,\"data\") ## generating a directory for data. Generate another one for models\n",
    "        #generate_dir(split_dir,delete_dir)\n",
    "        generate_lab_id_datasets(df,n_lab_ids,batch_size,impurity_ratio,split_dir,delete_dir,verbose)\n",
    "        \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating lab_id splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_splits_dir = os.path.join(os.path.join(pca_16_48comp_dir,\"full_train_splits\"))\n",
    "full_train_splits_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_0/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_0/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 1/10 [01:39<14:59, 99.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_0/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_1/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_1/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 2/10 [03:18<13:17, 99.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_1/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_2/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_2/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 3/10 [04:56<11:32, 98.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_2/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_3/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_3/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 4/10 [06:34<09:51, 98.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_3/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_4/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_4/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 5/10 [08:15<08:17, 99.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_4/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_5/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_5/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 6/10 [09:56<06:39, 99.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_5/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_6/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_6/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 7/10 [11:37<05:00, 100.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_6/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_7/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_7/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 8/10 [13:17<03:20, 100.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_7/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_8/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_8/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 9/10 [14:55<01:39, 99.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_8/json/batch_names.json\n",
      "Done.\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_9/data\n",
      "Creating directory /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_9/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [16:32<00:00, 99.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping json with batch names...\n",
      "Dumping json with batch names in /home/rio/data_sets/genetic_engineering_attribution/pca_engineered_datasets/pca_16_48comp/full_train_splits/split_9/json/batch_names.json\n",
      "Done.\n",
      "CPU times: user 15min 59s, sys: 28.3 s, total: 16min 28s\n",
      "Wall time: 16min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(8773)\n",
    "n_splits = 10\n",
    "n_lab_ids=146\n",
    "batch_size=1000\n",
    "impurity_ratio=8\n",
    "savedir = full_train_splits_dir\n",
    "delete_dir = True\n",
    "verbose=False\n",
    "generate_splits(df_full_train,n_splits,n_lab_ids,batch_size,impurity_ratio,savedir,delete_dir,verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try a simple random forest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:genetic_attribution]",
   "language": "python",
   "name": "conda-env-genetic_attribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
